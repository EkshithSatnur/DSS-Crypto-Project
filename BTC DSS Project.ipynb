{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7594140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Collected and cleaned 200 posts (with comments) from 4 subreddits.\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id='yZgp5fHdkhZQwGSCQ6Of4Q',\n",
    "    client_secret='yZgmiMH34SQlf2efwsf1zIeqWXEvoQ',\n",
    "    user_agent='Bitcoin Sentiment Analysis'\n",
    ")\n",
    "\n",
    "# List of subreddits\n",
    "subreddits = ['Bitcoin', 'CryptoCurrency', 'BitcoinMarkets', 'btc']  \n",
    "posts = []\n",
    "\n",
    "# Clean text utility\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s.,!?]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "# Loop through each subreddit\n",
    "for subreddit_name in subreddits:\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    \n",
    "    # Fetch 50 posts per subreddit with keyword \"Bitcoin\"\n",
    "    for submission in subreddit.search('Bitcoin', limit=50):\n",
    "        try:\n",
    "            submission.comments.replace_more(limit=0)\n",
    "            # Extract up to 20 top-level comments\n",
    "            top_comments = [comment.body for comment in submission.comments.list()[:20]]\n",
    "            comment_text = \" \".join([clean_text(comment) for comment in top_comments])\n",
    "            \n",
    "            title_clean = clean_text(submission.title)\n",
    "            selftext_clean = clean_text(submission.selftext)\n",
    "            combined_text = f\"{title_clean} {selftext_clean} {comment_text}\"\n",
    "            \n",
    "            posts.append([\n",
    "                title_clean,\n",
    "                selftext_clean,\n",
    "                comment_text,\n",
    "                combined_text,\n",
    "                datetime.utcfromtimestamp(submission.created_utc),\n",
    "                subreddit_name\n",
    "            ])\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Skipping a post in r/{subreddit_name} due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_reddit = pd.DataFrame(posts, columns=['title', 'selftext', 'comments', 'content', 'created_utc', 'subreddit'])\n",
    "print(f\"‚úÖ Collected and cleaned {len(df_reddit)} posts (with comments) from {len(subreddits)} subreddits.\")\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "279205ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "\n",
    "def get_finbert_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    scores = softmax(logits.numpy()[0])\n",
    "    sentiment = scores[2] - scores[0]  # Positive - Negative\n",
    "    return sentiment\n",
    "\n",
    "df_reddit['content'] = df_reddit['title'] + ' ' + df_reddit['selftext'] + ' ' + df_reddit['comments']\n",
    "\n",
    "df_reddit['sentiment'] = df_reddit['content'].apply(get_finbert_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a0e238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "btc_data.columns: Index(['Datetime', 'Close', 'High', 'Low', 'Open', 'Volume'], dtype='object', name='Price')\n",
      "\n",
      "Bitcoin Price Data (Last 10 Days - Hourly):\n",
      "Price                  Datetime          Close           High            Low  \\\n",
      "0     2025-04-30 18:00:00+00:00   94103.210938   94447.710938   94047.625000   \n",
      "1     2025-04-30 19:00:00+00:00   94237.242188   94237.242188   93769.265625   \n",
      "2     2025-04-30 20:00:00+00:00   94653.367188   94721.539062   94168.609375   \n",
      "3     2025-04-30 21:00:00+00:00   94419.125000   94733.960938   94419.125000   \n",
      "4     2025-04-30 22:00:00+00:00   94120.554688   94700.273438   94105.445312   \n",
      "..                          ...            ...            ...            ...   \n",
      "714   2025-05-30 12:00:00+00:00  105738.054688  105969.914062  105310.445312   \n",
      "715   2025-05-30 13:00:00+00:00  105535.015625  105956.718750  105439.250000   \n",
      "716   2025-05-30 14:00:00+00:00  105411.601562  105825.414062  105120.132812   \n",
      "717   2025-05-30 15:00:00+00:00  105571.359375  105797.320312  105389.445312   \n",
      "718   2025-05-30 16:00:00+00:00  105262.054688  105543.328125  105262.054688   \n",
      "\n",
      "Price           Open      Volume  \n",
      "0       94111.812500           0  \n",
      "1       94138.515625           0  \n",
      "2       94168.609375  1064081408  \n",
      "3       94595.007812           0  \n",
      "4       94547.007812           0  \n",
      "..               ...         ...  \n",
      "714    105899.851562           0  \n",
      "715    105704.359375  6964768768  \n",
      "716    105673.539062  7670505472  \n",
      "717    105403.039062  8241524736  \n",
      "718    105543.328125  1612722176  \n",
      "\n",
      "[719 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define time range\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=30)\n",
    "\n",
    "# Download BTC data\n",
    "btc_data = yf.download('BTC-USD', start=start_date, end=end_date, interval='1h')\n",
    "\n",
    "# Fix multilevel columns\n",
    "if isinstance(btc_data.columns, pd.MultiIndex):\n",
    "    btc_data.columns = btc_data.columns.get_level_values(0)  # Keep just the first level\n",
    "\n",
    "# Reset index\n",
    "btc_data.reset_index(inplace=True)\n",
    "\n",
    "# Rename 'index' or confirm 'Datetime' exists\n",
    "btc_data.rename(columns={'index': 'Datetime'}, inplace=True)\n",
    "\n",
    "# Confirm column structure\n",
    "print(\"btc_data.columns:\", btc_data.columns)\n",
    "\n",
    "print(\"\\nBitcoin Price Data (Last 30 Days - Hourly):\")\n",
    "print(btc_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d426213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vineeth\\AppData\\Local\\Temp\\ipykernel_1492\\112633328.py:6: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_reddit['hour'] = df_reddit['created_utc'].dt.floor('H')\n",
      "C:\\Users\\Vineeth\\AppData\\Local\\Temp\\ipykernel_1492\\112633328.py:7: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  btc_data['hour'] = btc_data['Datetime'].dt.floor('H')\n",
      "C:\\Users\\Vineeth\\AppData\\Local\\Temp\\ipykernel_1492\\112633328.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['sentiment'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Remove timezone from Reddit timestamps\n",
    "df_reddit['created_utc'] = pd.to_datetime(df_reddit['created_utc']).dt.tz_localize(None)\n",
    "btc_data['Datetime'] = pd.to_datetime(btc_data['Datetime']).dt.tz_localize(None)\n",
    "\n",
    "# Create hourly timestamps\n",
    "df_reddit['hour'] = df_reddit['created_utc'].dt.floor('H')\n",
    "btc_data['hour'] = btc_data['Datetime'].dt.floor('H')\n",
    "\n",
    "# Group Reddit sentiment by hour\n",
    "sentiment_hourly = df_reddit.groupby('hour', as_index=False)['sentiment'].mean()\n",
    "\n",
    "# ‚úÖ Ensure btc_data has no MultiIndex\n",
    "btc_data.columns = [col if isinstance(col, str) else col[0] for col in btc_data.columns]\n",
    "\n",
    "# ‚úÖ Merge on the hour column\n",
    "data = pd.merge(btc_data, sentiment_hourly, on='hour', how='left')\n",
    "\n",
    "# Fill missing sentiment with neutral\n",
    "data['sentiment'].fillna(0, inplace=True)\n",
    "\n",
    "# Select required columns\n",
    "data = data[['Datetime', 'Close', 'sentiment']]\n",
    "\n",
    "# Normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data[['Close', 'sentiment']] = scaler.fit_transform(data[['Close', 'sentiment']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580392c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 9s 236ms/step - loss: 0.0663 - val_loss: 0.0150\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0019 - val_loss: 9.9257e-04\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0020 - val_loss: 9.3291e-04\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0020 - val_loss: 9.9231e-04\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0019 - val_loss: 9.9422e-04\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 0.0019 - val_loss: 8.8680e-04\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0018 - val_loss: 8.7157e-04\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 3s 203ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.0021 - val_loss: 9.3503e-04\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.0017 - val_loss: 8.6499e-04\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 3s 203ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 0.0017 - val_loss: 9.6824e-04\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 0.0020 - val_loss: 8.5955e-04\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 0.0017 - val_loss: 8.9398e-04\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 3s 207ms/step - loss: 0.0018 - val_loss: 8.0273e-04\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 3s 209ms/step - loss: 0.0017 - val_loss: 9.2928e-04\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 0.0018 - val_loss: 7.9796e-04\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.0018 - val_loss: 8.4539e-04\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.0016 - val_loss: 7.9334e-04\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 3s 207ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 3s 205ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 3s 205ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 3s 208ms/step - loss: 0.0016 - val_loss: 7.9709e-04\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.0015 - val_loss: 7.7705e-04\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.0017 - val_loss: 7.6654e-04\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0018 - val_loss: 7.5829e-04\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0016 - val_loss: 9.9715e-04\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0016 - val_loss: 8.2593e-04\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 0.0014 - val_loss: 9.1446e-04\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 0.0016 - val_loss: 7.5656e-04\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 0.0016 - val_loss: 8.3897e-04\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0014 - val_loss: 7.4928e-04\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0017 - val_loss: 8.3750e-04\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0016 - val_loss: 7.3436e-04\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0016 - val_loss: 8.5398e-04\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0014 - val_loss: 7.1248e-04\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0016 - val_loss: 9.0575e-04\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.0015 - val_loss: 6.9618e-04\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0016 - val_loss: 9.3196e-04\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 0.0017 - val_loss: 7.2382e-04\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0017 - val_loss: 7.0509e-04\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0018 - val_loss: 6.8492e-04\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.0016 - val_loss: 9.2324e-04\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 0.0019 - val_loss: 7.5475e-04\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.0016 - val_loss: 9.4197e-04\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.0015 - val_loss: 6.8849e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ada905bb20>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "def create_sequences(data, time_steps=90):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data[i:i + time_steps])\n",
    "        y.append(data[i + time_steps, 0])  # Close price\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "dataset = data[['Close', 'sentiment']].values\n",
    "time_steps = 90\n",
    "X, y = create_sequences(dataset,time_steps)\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),\n",
    "    Dropout(0.1),\n",
    "    LSTM(128),\n",
    "    Dropout(0.1),\n",
    "    Dense(1)\n",
    "])\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bca1fdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Hourly Forecasted BTC Price Fluctuations:\n",
      "\n",
      "Hour  1: Predicted Price = $105,546.93 | Change = +0.27% ‚Üë\n",
      "Hour  2: Predicted Price = $105,536.26 | Change = -0.01% ‚Üì\n",
      "Hour  3: Predicted Price = $105,546.27 | Change = +0.01% ‚Üë\n",
      "Hour  4: Predicted Price = $105,565.45 | Change = +0.02% ‚Üë\n",
      "Hour  5: Predicted Price = $105,589.52 | Change = +0.02% ‚Üë\n",
      "Hour  6: Predicted Price = $105,616.53 | Change = +0.03% ‚Üë\n",
      "Hour  7: Predicted Price = $105,645.25 | Change = +0.03% ‚Üë\n",
      "Hour  8: Predicted Price = $105,674.80 | Change = +0.03% ‚Üë\n",
      "Hour  9: Predicted Price = $105,704.54 | Change = +0.03% ‚Üë\n",
      "Hour 10: Predicted Price = $105,733.97 | Change = +0.03% ‚Üë\n",
      "Hour 11: Predicted Price = $105,762.78 | Change = +0.03% ‚Üë\n",
      "Hour 12: Predicted Price = $105,790.72 | Change = +0.03% ‚Üë\n",
      "Hour 13: Predicted Price = $105,817.69 | Change = +0.03% ‚Üë\n",
      "Hour 14: Predicted Price = $105,843.63 | Change = +0.02% ‚Üë\n",
      "Hour 15: Predicted Price = $105,868.57 | Change = +0.02% ‚Üë\n",
      "Hour 16: Predicted Price = $105,892.54 | Change = +0.02% ‚Üë\n",
      "Hour 17: Predicted Price = $105,915.65 | Change = +0.02% ‚Üë\n",
      "Hour 18: Predicted Price = $105,937.97 | Change = +0.02% ‚Üë\n",
      "Hour 19: Predicted Price = $105,959.61 | Change = +0.02% ‚Üë\n",
      "Hour 20: Predicted Price = $105,980.67 | Change = +0.02% ‚Üë\n",
      "Hour 21: Predicted Price = $106,001.25 | Change = +0.02% ‚Üë\n",
      "Hour 22: Predicted Price = $106,021.41 | Change = +0.02% ‚Üë\n",
      "Hour 23: Predicted Price = $106,041.23 | Change = +0.02% ‚Üë\n",
      "Hour 24: Predicted Price = $106,060.76 | Change = +0.02% ‚Üë\n",
      "Hour 25: Predicted Price = $106,080.04 | Change = +0.02% ‚Üë\n",
      "Hour 26: Predicted Price = $106,099.10 | Change = +0.02% ‚Üë\n",
      "Hour 27: Predicted Price = $106,117.97 | Change = +0.02% ‚Üë\n",
      "Hour 28: Predicted Price = $106,136.66 | Change = +0.02% ‚Üë\n",
      "Hour 29: Predicted Price = $106,155.17 | Change = +0.02% ‚Üë\n",
      "Hour 30: Predicted Price = $106,173.50 | Change = +0.02% ‚Üë\n",
      "Hour 31: Predicted Price = $106,191.65 | Change = +0.02% ‚Üë\n",
      "Hour 32: Predicted Price = $106,209.61 | Change = +0.02% ‚Üë\n",
      "Hour 33: Predicted Price = $106,227.39 | Change = +0.02% ‚Üë\n",
      "Hour 34: Predicted Price = $106,244.96 | Change = +0.02% ‚Üë\n",
      "Hour 35: Predicted Price = $106,262.33 | Change = +0.02% ‚Üë\n",
      "Hour 36: Predicted Price = $106,279.49 | Change = +0.02% ‚Üë\n",
      "Hour 37: Predicted Price = $106,296.43 | Change = +0.02% ‚Üë\n",
      "Hour 38: Predicted Price = $106,313.15 | Change = +0.02% ‚Üë\n",
      "Hour 39: Predicted Price = $106,329.65 | Change = +0.02% ‚Üë\n",
      "Hour 40: Predicted Price = $106,345.93 | Change = +0.02% ‚Üë\n",
      "Hour 41: Predicted Price = $106,361.99 | Change = +0.02% ‚Üë\n",
      "Hour 42: Predicted Price = $106,377.81 | Change = +0.01% ‚Üë\n",
      "Hour 43: Predicted Price = $106,393.42 | Change = +0.01% ‚Üë\n",
      "Hour 44: Predicted Price = $106,408.81 | Change = +0.01% ‚Üë\n",
      "Hour 45: Predicted Price = $106,423.98 | Change = +0.01% ‚Üë\n",
      "Hour 46: Predicted Price = $106,438.93 | Change = +0.01% ‚Üë\n",
      "Hour 47: Predicted Price = $106,453.67 | Change = +0.01% ‚Üë\n",
      "Hour 48: Predicted Price = $106,468.20 | Change = +0.01% ‚Üë\n",
      "Hour 49: Predicted Price = $106,482.53 | Change = +0.01% ‚Üë\n",
      "Hour 50: Predicted Price = $106,496.65 | Change = +0.01% ‚Üë\n",
      "Hour 51: Predicted Price = $106,510.57 | Change = +0.01% ‚Üë\n",
      "Hour 52: Predicted Price = $106,524.30 | Change = +0.01% ‚Üë\n",
      "Hour 53: Predicted Price = $106,537.83 | Change = +0.01% ‚Üë\n",
      "Hour 54: Predicted Price = $106,551.17 | Change = +0.01% ‚Üë\n",
      "Hour 55: Predicted Price = $106,564.32 | Change = +0.01% ‚Üë\n",
      "Hour 56: Predicted Price = $106,577.28 | Change = +0.01% ‚Üë\n",
      "Hour 57: Predicted Price = $106,590.07 | Change = +0.01% ‚Üë\n",
      "Hour 58: Predicted Price = $106,602.66 | Change = +0.01% ‚Üë\n",
      "Hour 59: Predicted Price = $106,615.08 | Change = +0.01% ‚Üë\n",
      "Hour 60: Predicted Price = $106,627.33 | Change = +0.01% ‚Üë\n",
      "Hour 61: Predicted Price = $106,639.39 | Change = +0.01% ‚Üë\n",
      "Hour 62: Predicted Price = $106,651.29 | Change = +0.01% ‚Üë\n",
      "Hour 63: Predicted Price = $106,663.01 | Change = +0.01% ‚Üë\n",
      "Hour 64: Predicted Price = $106,674.56 | Change = +0.01% ‚Üë\n",
      "Hour 65: Predicted Price = $106,685.95 | Change = +0.01% ‚Üë\n",
      "Hour 66: Predicted Price = $106,697.17 | Change = +0.01% ‚Üë\n",
      "Hour 67: Predicted Price = $106,708.23 | Change = +0.01% ‚Üë\n",
      "Hour 68: Predicted Price = $106,719.13 | Change = +0.01% ‚Üë\n",
      "Hour 69: Predicted Price = $106,729.87 | Change = +0.01% ‚Üë\n",
      "Hour 70: Predicted Price = $106,740.44 | Change = +0.01% ‚Üë\n",
      "Hour 71: Predicted Price = $106,750.87 | Change = +0.01% ‚Üë\n",
      "Hour 72: Predicted Price = $106,761.14 | Change = +0.01% ‚Üë\n",
      "\n",
      "üîÆ Final Forecast Summary:\n",
      "‚úÖ Yes, the price is increasing by 1.42% in the next 72 hours.\n"
     ]
    }
   ],
   "source": [
    "# Get forecast horizon from the user\n",
    "forecast_hours = int(input(\"Enter how many hours ahead you'd like to forecast (e.g., 24, 48, 168): \"))\n",
    "\n",
    "# Forecast loop\n",
    "last_sequence = dataset[-time_steps:]\n",
    "forecast_input = last_sequence.copy()\n",
    "forecast_prices = []\n",
    "\n",
    "for _ in range(forecast_hours):\n",
    "    input_seq = np.expand_dims(forecast_input[-time_steps:], axis=0)\n",
    "    pred = model.predict(input_seq, verbose=0)[0][0]\n",
    "    forecast_prices.append(pred)\n",
    "    forecast_input = np.vstack([forecast_input, [pred, forecast_input[-1][1]]])  # Use last sentiment\n",
    "\n",
    "# Decode forecasted prices\n",
    "decoded_prices = [scaler.inverse_transform([[p, 0]])[0][0] for p in forecast_prices]\n",
    "last_actual_price = scaler.inverse_transform([[dataset[-1][0], 0]])[0][0]\n",
    "\n",
    "# Calculate percentage fluctuations hour by hour\n",
    "print(\"\\nüìà Hourly Forecasted BTC Price Fluctuations:\\n\")\n",
    "prev_price = last_actual_price\n",
    "for i, price in enumerate(decoded_prices):\n",
    "    change = ((price - prev_price) / prev_price) * 100\n",
    "    direction = \"‚Üë\" if change > 0 else \"‚Üì\" if change < 0 else \"‚Üí\"\n",
    "    print(f\"Hour {i+1:>2}: Predicted Price = ${price:,.2f} | Change = {change:+.2f}% {direction}\")\n",
    "    prev_price = price\n",
    "\n",
    "# Final summary\n",
    "final_predicted_price = decoded_prices[-1]\n",
    "percentage_change = ((final_predicted_price - last_actual_price) / last_actual_price) * 100\n",
    "\n",
    "print(\"\\nüîÆ Final Forecast Summary:\")\n",
    "\n",
    "if percentage_change > 0.1:\n",
    "    print(f\"‚úÖ Yes, the price is increasing by {percentage_change:.2f}% in the next {forecast_hours} hours.\")\n",
    "elif percentage_change < -0.1:\n",
    "    print(f\"‚ùå No, the price is decreasing by {abs(percentage_change):.2f}% in the next {forecast_hours} hours.\")\n",
    "else:\n",
    "    print(f\"‚öñÔ∏è The predicted change is negligible ({percentage_change:.2f}%) in the next {forecast_hours} hours.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55574cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 54ms/step\n",
      "\n",
      "üìä Evaluation Metrics:\n",
      "MSE:  227553.6966\n",
      "RMSE: 477.0259\n",
      "R¬≤ Score: 0.8918\n",
      "üîê Model Confidence Score: 89.18%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform\n",
    "y_pred_inv = scaler.inverse_transform(np.c_[y_pred, np.zeros(len(y_pred))])[:, 0]\n",
    "y_test_inv = scaler.inverse_transform(np.c_[y_test, np.zeros(len(y_test))])[:, 0]\n",
    "\n",
    "# Evaluation metrics\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "def get_confidence_score(r2_score):\n",
    "    if r2_score < 0:\n",
    "        return 0\n",
    "    elif r2_score > 1:\n",
    "        return 100\n",
    "    else:\n",
    "        return round(r2_score * 100, 2)\n",
    "\n",
    "confidence_score = get_confidence_score(r2)\n",
    "\n",
    "print(f\"\\nüìä Evaluation Metrics:\")\n",
    "print(f\"MSE:  {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n",
    "print(f\"üîê Model Confidence Score: {confidence_score:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864210dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
